services:
  cu124_torch25_base:
    build:
      context: .
      dockerfile: cu124_torch25_base/Dockerfile
      args:
        # pass through env vars to docker build
        DOCKER_USER: $DOCKER_USER
        HF_TOKEN: $HF_TOKEN
        USERNAME: $USER
    image: cu124_torch25_base:latest

  vlm-caption:
    build:
      context: .
      dockerfile: Dockerfile
    shm_size: '16gb'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    environment:
      - HF_TOKEN=${HF_TOKEN}
    image: vlm-caption
    depends_on:
      - cu124_torch25_base
    volumes:
      - ./data:/data
    stdin_open: true
    tty: true

  salesforce_blip2:
    build:
      context: .
      dockerfile: Salesforce/blip2/Dockerfile
      args:
        GIT_DOMAIN: huggingface.co
        GIT_ORG: Salesforce
        GIT_REPO: blip2-opt-6.7b-coco
        GIT_BRANCH: main
        DIR: Salesforce/blip2
    shm_size: '16gb'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    image: salesforce_blip2
    depends_on:
      - cu124_torch25_base
    volumes:
      - ./data:/data
    stdin_open: true
    tty: true
  # Qwen/Qwen2-VL-7B-Instruct
  qwen2_vl_7b_instruct:
    build:
      context: .
      dockerfile: qwen/qwen2-vl/Dockerfile
      args:
        GIT_DOMAIN: huggingface.co
        GIT_ORG: Qwen
        GIT_REPO: Qwen2-VL-7B-Instruct
        GIT_BRANCH: main
        DIR: qwen/qwen2-vl/
    shm_size: '16gb'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    image: qwen2_vl_7b_instruct
    depends_on:
      - cu124_torch25_base
    volumes:
      - ./data:/data
    stdin_open: true
    tty: true

  # fancyfeast/llama-joycaption-alpha-two-hf-llava
  joycaption-alpha-two:
    build:
      context: .
      dockerfile: fancyfeast/llama-joycaption-alpha-two-hf-llava/Dockerfile
      args:
        GIT_DOMAIN: huggingface.co
        GIT_ORG: fancyfeast
        GIT_REPO: llama-joycaption-alpha-two-hf-llava
        GIT_BRANCH: main
        DIR: fancyfeast/llama-joycaption-alpha-two-hf-llava/
    shm_size: '16gb'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    environment:
      - HF_TOKEN=${HF_TOKEN}
    image: joycaption-alpha-two
    depends_on:
      - cu124_torch25_base
    volumes:
      - ./data:/data
    stdin_open: true
    tty: true
    networks:
      - isolated_network
  # microsoft/Florence-2
  florence-2:
    build:
      context: .
      dockerfile: microsoft/florence-2/Dockerfile
      args:
        GIT_DOMAIN: huggingface.co
        GIT_ORG: microsoft
        GIT_REPO: Florence-2-large
        GIT_BRANCH: main
        DIR: microsoft/florence-2/
    shm_size: '16gb'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    environment:
      - HF_TOKEN=${HF_TOKEN}
    image: florence-2
    depends_on:
      - cu124_torch25_base
    volumes:
      - ./data:/data
    stdin_open: true
    tty: true

networks:
    isolated_network:
        driver: bridge
        internal: true
